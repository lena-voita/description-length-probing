

// This imports the defaults, which can be overridden below.
include "[path_to_the_repo]/jiant/config/defaults.conf"  // relative path to this file                  // CHANGE THIS!!!

data_dir = "[path_to_the_data]"  // Base directory in which to look for raw data subdirectories. This   // CHANGE THIS!!!
                                 // could be the glue_data directory created by download_glue_data.py.


project_dir = "."  // The base directory for model output.  
exp_name = ""  // configure this
run_name = "run"  // default


// Task names: 
// "edges-pos-ontonotes", "edges-nonterminal-ontonotes", "edges-dep-ud-ewt", 
// "edges-srl-ontonotes", "edges-coref-ontonotes", "edges-rel-semeval", "edges-ner-ontonotes"
pretrain_tasks = "edges-pos-ontonotes"  // empty: don't run main training phase    // CHANGE THIS!!!
target_tasks = "edges-pos-ontonotes"   // train classifier only                    // CHANGE THIS!!!

// Eval will use task-specific params.
do_pretrain = 1        // skip main train phase
allow_untrained_encoder_parameters = 1  // allow skipping training phase
allow_missing_task_map = 1  // ignore missing classifier_task_map.json
do_target_task_training = 0  // train using eval task params
write_preds = "val,test"

lr_patience = 5  // vals until LR decay
patience = 10      // vals until early-stopping
min_epochs = 1 

input_module = "elmo"
tokenizer = MosesTokenizer
elmo_layer_index = 1  // ------>    --------->    --------->    -------->           //  CHANGE THIS!!!
word_embs_file = "" // should not be necessary for BERT
max_seq_len = 512
cove = 0

// Use no-op encoder (no params).
sent_enc = "none"
skip_embs = 1  // forward embeddings from lower level.
sep_embs_for_skip = 1  // use task embeddings since we skip the generic ones.

//---------------------------------------------------------------------------
// MDL
do_full_eval = 0
classifier = mlp
train_type = SamplingMultiTaskTrainerOnlineCoding

edgeprobe_cnn_context = 0  // Expanded context for edge probing via CNN.
                           // 0 looks at only the current word, 1 adds +/-
                           // words (kernel width 3), etc.
                           
keep_all_checkpoints = 0  // If set, keep checkpoint files from every validation. Otherwise, keep
                          // only the best and (if different) most recent.
                          
online_coding_load_checkpoint = 0 // Load from previous data portion 

online_coding_portion_split = "0.001,0.002,0.004,0.008,0.016,0.032,0.0625,0.125,0.25,0.5,1"

online_coding_pre_shuffle = 1
online_coding_pre_shuffle_seed = 1234
early_stopping_metric = xent







